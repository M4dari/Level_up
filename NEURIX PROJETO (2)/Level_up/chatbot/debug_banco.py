import chromadb
from sentence_transformers import SentenceTransformer
import os

CHROMA_PATH = "./chroma_db"
COLLECTION_NAME = "documentos_vivo"

def debug_banco():
    """Debug completo do banco ChromaDB"""
    try:
        print("ğŸ” Debugando banco ChromaDB...")
        
        # Verificar se a pasta do banco existe
        if not os.path.exists(CHROMA_PATH):
            print(f"âŒ Pasta {CHROMA_PATH} nÃ£o existe!")
            return
        
        # Conectar ao banco
        chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)
        chroma_collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)
        
        # InformaÃ§Ãµes bÃ¡sicas
        count = chroma_collection.count()
        print(f"ğŸ“Š Total de documentos: {count}")
        
        if count == 0:
            print("âŒ Banco estÃ¡ vazio!")
            return
        
        # Pegar alguns documentos para anÃ¡lise
        resultados = chroma_collection.get(limit=3)
        
        print(f"\nğŸ“‹ Primeiros 3 documentos:")
        for i, doc in enumerate(resultados['documents'][:3]):
            print(f"{i+1}. {doc[:150]}...")
        
        # Teste de busca simples
        print(f"\nğŸ§ª Testando busca por 'onboarding'...")
        
        # Carregar o modelo atual (mesmo do chatbot)
        print("ğŸ”„ Carregando modelo de embedding...")
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Gerar embedding da pergunta
        pergunta = "onboarding"
        question_embedding = embedding_model.encode([pergunta]).tolist()
        
        # Fazer busca
        busca_resultados = chroma_collection.query(
            query_embeddings=question_embedding,
            n_results=3
        )
        
        documentos_encontrados = busca_resultados['documents'][0]
        distancias = busca_resultados['distances'][0]
        
        print(f"ğŸ“ Documentos encontrados: {len(documentos_encontrados)}")
        
        if documentos_encontrados:
            print("âœ… BUSCA FUNCIONOU!")
            for i, (doc, dist) in enumerate(zip(documentos_encontrados, distancias)):
                print(f"{i+1}. (DistÃ¢ncia: {dist:.3f}) {doc[:100]}...")
        else:
            print("âŒ BUSCA NÃƒO RETORNOU RESULTADOS!")
            
        # Teste com diferentes palavras-chave
        print(f"\nğŸ§ª Testando outras palavras-chave...")
        palavras_teste = ["vivo", "empresa", "trabalho", "colaborador"]
        
        for palavra in palavras_teste:
            try:
                word_embedding = embedding_model.encode([palavra]).tolist()
                resultado_teste = chroma_collection.query(
                    query_embeddings=word_embedding,
                    n_results=1
                )
                
                if resultado_teste['documents'][0]:
                    print(f"âœ… '{palavra}': Encontrou documento")
                else:
                    print(f"âŒ '{palavra}': NÃ£o encontrou")
            except:
                print(f"âŒ '{palavra}': Erro na busca")
                
    except Exception as e:
        print(f"âŒ Erro no debug: {str(e)}")
        import traceback
        traceback.print_exc()

def reindexar_com_modelo_correto():
    """Reindexar documentos com o modelo correto"""
    print("\n" + "="*50)
    print("ğŸ”„ REINDEXAÃ‡ÃƒO COM MODELO CORRETO")
    print("="*50)
    
    try:
        # 1. Limpar banco atual
        chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)
        
        try:
            chroma_client.delete_collection(name=COLLECTION_NAME)
            print("ğŸ—‘ï¸ ColeÃ§Ã£o antiga removida")
        except:
            print("â„¹ï¸ ColeÃ§Ã£o nÃ£o existia")
            
        # 2. Criar nova coleÃ§Ã£o
        chroma_collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)
        print("âœ… Nova coleÃ§Ã£o criada")
        
        # 3. Verificar se existe pasta de documentos
        if not os.path.exists('./documentos'):
            print("âŒ Pasta 'documentos' nÃ£o encontrada!")
            print("ğŸ’¡ Crie a pasta 'documentos' e coloque seus PDFs lÃ¡")
            return
            
        # 4. Verificar se hÃ¡ arquivos na pasta
        arquivos = [f for f in os.listdir('./documentos') if f.lower().endswith(('.pdf', '.txt', '.docx'))]
        if not arquivos:
            print("âŒ Nenhum documento encontrado na pasta 'documentos'!")
            print("ğŸ’¡ Adicione arquivos PDF, TXT ou DOCX na pasta")
            return
            
        print(f"ğŸ“ Encontrados {len(arquivos)} arquivos: {arquivos}")
        
        # 5. Reindexar com LlamaIndex
        from llama_index.core import SimpleDirectoryReader
        from llama_index.core.node_parser import SentenceSplitter
        
        print("ğŸ“ Carregando documentos da pasta...")
        documentos = SimpleDirectoryReader(input_dir='documentos')
        docs = documentos.load_data()
        
        print(f"ğŸ“„ {len(docs)} pÃ¡ginas carregadas")
        
        # 6. Dividir em chunks
        node_parser = SentenceSplitter(chunk_size=350)
        nodes = node_parser.get_nodes_from_documents(docs, show_progress=True)
        
        print(f"ğŸ“ {len(nodes)} chunks criados")
        
        # 7. Gerar embeddings com modelo correto
        print("ğŸ”„ Carregando modelo de embedding...")
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        ids = [node.id_ for node in nodes]
        documents = [node.text for node in nodes]
        metadatas = [node.metadata for node in nodes]
        
        print("ğŸ”„ Gerando embeddings...")
        embeddings = embedding_model.encode(documents, batch_size=16, show_progress_bar=True).tolist()
        
        # 8. Adicionar ao ChromaDB
        print("ğŸ’¾ Salvando no banco...")
        chroma_collection.add(
            ids=ids,
            documents=documents,
            metadatas=metadatas,
            embeddings=embeddings
        )
        
        print(f"âœ… {len(documents)} chunks reindexados com sucesso!")
        
    except Exception as e:
        print(f"âŒ Erro na reindexaÃ§Ã£o: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ DIAGNÃ“STICO DO CHATBOT")
    print("="*50)
    
    debug_banco()
    
    print(f"\n" + "="*50)
    resposta = input("â“ Deseja reindexar com o modelo correto? (s/n): ").lower().strip()
    
    if resposta == 's':
        reindexar_com_modelo_correto()
        print("\nğŸ§ª Testando novamente apÃ³s reindexaÃ§Ã£o...")
        debug_banco()
    else:
        print("ğŸ’¡ Para resolver o problema, execute este script novamente e escolha 's'")
        print("ğŸ’¡ Ou ajuste o modelo no chatbot.py para usar o mesmo modelo dos embeddings originais")